{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from csvvalidator import *\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "09f619e978197081a290acf626007b655d5ee171"
   },
   "outputs": [],
   "source": [
    "#Validate data\n",
    "field_names = (\n",
    "               'Ticket number',\n",
    "               'Issue Date',\n",
    "               'Latitude',\n",
    "               'Longitude',\n",
    "               'Issue time',\n",
    "               'Violation Description'\n",
    "               )\n",
    "validator = CSVValidator(field_names)\n",
    "# basic header and record length checks\n",
    "validator.add_header_check('EX1', 'bad header')\n",
    "validator.add_record_length_check('EX2', 'unexpected record length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ddlin/23122971/ipykernel_3579349/3233484126.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../parking_citation_2020_2022.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../parking_citation_2020_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "ede4493e4dc3099a4c74b487e757fe29e7845c7b"
   },
   "outputs": [],
   "source": [
    "#updating formatting so that I can translate issue date to datetime\n",
    "df['Issue Date'] = df[df['Issue Date'].notnull()]['Issue Date'].apply(lambda x: x.split('T')[0])\n",
    "df['Issue Date'] = pd.to_datetime(df['Issue Date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "e81ae7fa7a879cb3b6d5fe17fc9a3461e482117b"
   },
   "outputs": [],
   "source": [
    "#pad anything that is less than 4 digits then isolate just the hours\n",
    "df['Issue time'] = df['Issue time'].astype(str)\n",
    "df['Issue time'] = df['Issue time'].apply(lambda x: x.split('.')[0])\n",
    "df['Issue time'] = df[df['Issue time'].notnull()]['Issue time'].apply(lambda x: x.zfill(4))\n",
    "df['Issue Hour'] = df[df['Issue time']!='0nan']['Issue time'].apply(lambda x: DT.datetime.strptime(x,'%H%M').hour)\n",
    "\n",
    "#clean lat lon\n",
    "df['Latitude'] = np.where(df['Latitude']==99999.000, np.nan, df['Latitude'])\n",
    "df['Longitude'] = np.where(df['Longitude']==99999.000, np.nan, df['Longitude'])\n",
    "\n",
    "#string for ticketnum\n",
    "df['Ticket number'] = df['Ticket number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "48549d3f8fa12346edc866ec252b8dd414667708"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/homezvol2/ddlin/mambaforge-pypy3/envs/plotly/lib/python3.8/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/tmp/ddlin/23122971/ipykernel_3579349/1413484023.py:5: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  x2m,y2m = pyproj.transform(pyproj.Proj(pm,preserve_units = True), pyproj.Proj(\"+init=epsg:4326\"), x1m,y1m)\n"
     ]
    }
   ],
   "source": [
    "#Updating the Lat Lon\n",
    "import pyproj\n",
    "pm = '+proj=lcc +lat_1=34.03333333333333 +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 +x_0=2000000 +y_0=500000.0000000002 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs'\n",
    "x1m,y1m = df['Latitude'].values, df['Longitude'].values\n",
    "x2m,y2m = pyproj.transform(pyproj.Proj(pm,preserve_units = True), pyproj.Proj(\"+init=epsg:4326\"), x1m,y1m)\n",
    "df['Latitude']=x2m\n",
    "df['Longitude']=y2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../cleaned_2022_parking_citation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time',\n",
       "       'RP State Plate', 'Plate Expiry Date', 'VIN', 'Make', 'Body Style',\n",
       "       'Color', 'Location', 'Route', 'Agency', 'Violation code',\n",
       "       'Violation Description', 'Fine amount', 'Latitude', 'Longitude',\n",
       "       'Agency Description', 'Color Description', 'Body Style Description',\n",
       "       'Issue Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PASSENGER CAR    4806029\n",
       " PICK-UP TRUCK     165537\n",
       " VAN                91295\n",
       " COMMERCIAL         76050\n",
       " TRUCK              67966\n",
       " TRAILER            38114\n",
       " MOTOR HOME         20603\n",
       " BUS                 1680\n",
       " LIMOUSINE            239\n",
       " Name: Body Style Description, dtype: int64,\n",
       " PA    4806029\n",
       " PU     165537\n",
       " VN      91295\n",
       " TK      67966\n",
       " CM      64129\n",
       "        ...   \n",
       " RB          1\n",
       " 02          1\n",
       " FB          1\n",
       " RX          1\n",
       " AU          1\n",
       " Name: Body Style, Length: 133, dtype: int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body Style Description'].value_counts(), df['Body Style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5308775, 23)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RP State Plate</th>\n",
       "      <th>Make</th>\n",
       "      <th>Body Style</th>\n",
       "      <th>Color Description</th>\n",
       "      <th>Agency Description</th>\n",
       "      <th>Issue Hour</th>\n",
       "      <th>Violation Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>MAZD</td>\n",
       "      <td>PA</td>\n",
       "      <td>GREY</td>\n",
       "      <td>54 - DOT - HOLLYWOOD</td>\n",
       "      <td>13.000</td>\n",
       "      <td>WHITE ZONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>LEXS</td>\n",
       "      <td>PA</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>51 - DOT - WESTERN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>MERZ</td>\n",
       "      <td>PA</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>51 - DOT - WESTERN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>PORS</td>\n",
       "      <td>PA</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>55 - DOT - SOUTHERN</td>\n",
       "      <td>2.000</td>\n",
       "      <td>STANDNG IN ALLEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>RROV</td>\n",
       "      <td>PA</td>\n",
       "      <td>GREY</td>\n",
       "      <td>51 - DOT - WESTERN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>PARKED ON SIDEWALK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RP State Plate  Make Body Style Color Description    Agency Description  \\\n",
       "0             CA  MAZD         PA              GREY  54 - DOT - HOLLYWOOD   \n",
       "1             CA  LEXS         PA             BLACK    51 - DOT - WESTERN   \n",
       "2             CA  MERZ         PA             BLACK    51 - DOT - WESTERN   \n",
       "3             CA  PORS         PA             BLACK   55 - DOT - SOUTHERN   \n",
       "4             CA  RROV         PA              GREY    51 - DOT - WESTERN   \n",
       "\n",
       "   Issue Hour Violation Description  \n",
       "0      13.000            WHITE ZONE  \n",
       "1      16.000                   NaN  \n",
       "2      16.000                   NaN  \n",
       "3       2.000      STANDNG IN ALLEY  \n",
       "4       1.000    PARKED ON SIDEWALK  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = df[[ 'RP State Plate', 'Make', 'Body Style', 'Color Description', 'Agency Description', 'Issue Hour', 'Violation Description']]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4859213, 7)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df[~data_df.isna().any(axis=1)]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by KMeans.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m coordinates \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create a KMeans clustering model with 100 clusters\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(coordinates)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Add cluster labels to the original dataframe\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mCluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/plotly/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1417\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \n\u001b[1;32m   1392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m-> 1417\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1418\u001b[0m     X,\n\u001b[1;32m   1419\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1420\u001b[0m     dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1421\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1422\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[1;32m   1423\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1424\u001b[0m )\n\u001b[1;32m   1426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1428\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/plotly/lib/python3.8/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/plotly/lib/python3.8/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    928\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 929\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    930\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    931\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    932\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    933\u001b[0m         )\n\u001b[1;32m    935\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    936\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required by KMeans."
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming your dataframe is named 'data' and has columns 'Latitude' and 'Longitude'\n",
    "coordinates = data_df[['Latitude', 'Longitude']].values\n",
    "\n",
    "# Create a KMeans clustering model with 100 clusters\n",
    "kmeans = KMeans(n_clusters=500, random_state=0).fit(coordinates)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket number</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Issue time</th>\n",
       "      <th>Meter Id</th>\n",
       "      <th>Marked Time</th>\n",
       "      <th>RP State Plate</th>\n",
       "      <th>Plate Expiry Date</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Make</th>\n",
       "      <th>Body Style</th>\n",
       "      <th>...</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Violation code</th>\n",
       "      <th>Violation Description</th>\n",
       "      <th>Fine amount</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Agency Description</th>\n",
       "      <th>Color Description</th>\n",
       "      <th>Body Style Description</th>\n",
       "      <th>Issue Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Ticket number, Issue Date, Issue time, Meter Id, Marked Time, RP State Plate, Plate Expiry Date, VIN, Make, Body Style, Color, Location, Route, Agency, Violation code, Violation Description, Fine amount, Latitude, Longitude, Agency Description, Color Description, Body Style Description, Issue Hour]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../cleaned_2022_parking_citation2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO PARK/STREET CLEAN    1291019\n",
       "METER EXP.               847889\n",
       "RED ZONE                 561345\n",
       "PREFERENTIAL PARKING     372800\n",
       "DISPLAY OF TABS          299580\n",
       "                         ...   \n",
       "PK ON PRIV ST                 1\n",
       "METER EXPIRED                 1\n",
       "22500I                        1\n",
       "REPAIRING VEH/STREET          1\n",
       "8009H                         1\n",
       "Name: Violation Description, Length: 88, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The label is imbalanced\n",
    "df['Violation Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tealeave/mambaforge/envs/d2l/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.9293214082717896\n",
      "Training Accuracy: 0.41698695931874435\n",
      "Epoch 2/10, Loss: 1.6889859437942505\n",
      "Training Accuracy: 0.42009175362271434\n",
      "Epoch 3/10, Loss: 2.048356294631958\n",
      "Training Accuracy: 0.42744758104085573\n",
      "Epoch 4/10, Loss: 1.808008074760437\n",
      "Training Accuracy: 0.4295431127539171\n",
      "Epoch 5/10, Loss: 1.8518352508544922\n",
      "Training Accuracy: 0.42972574771297417\n",
      "Epoch 6/10, Loss: 1.8611969947814941\n",
      "Training Accuracy: 0.43094013389595803\n",
      "Epoch 7/10, Loss: 1.907226800918579\n",
      "Training Accuracy: 0.43274058748487126\n",
      "Epoch 8/10, Loss: 2.0424554347991943\n",
      "Training Accuracy: 0.43207001733669165\n",
      "Epoch 9/10, Loss: 1.5820761919021606\n",
      "Training Accuracy: 0.43386570060951013\n",
      "Epoch 10/10, Loss: 1.8171765804290771\n",
      "Training Accuracy: 0.43538402407510385\n",
      "Total execution time: 165.24951720237732 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Check cuda\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "\n",
    "\n",
    "# 1. Data Preparation\n",
    "# ---------------------\n",
    "data = pd.read_csv(\"../cleaned_2022_parking_citation2.csv\")\n",
    "features = [ 'RP State Plate', 'Make', 'Body Style', 'Color Description', 'Agency Description', 'Issue Hour', 'Cluster']\n",
    "X = data[features]\n",
    "\n",
    "# One-hot encode all features\n",
    "ohe = OneHotEncoder(sparse=False, dtype=int)\n",
    "X_encoded = ohe.fit_transform(X)\n",
    "encoded_columns = ohe.get_feature_names_out(features)  # Get column names for the encoded columns\n",
    "X = pd.DataFrame(X_encoded, columns=encoded_columns)\n",
    "\n",
    "y = LabelEncoder().fit_transform(data['Violation Description'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "batch_size = 256\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 2. Model Definition\n",
    "# ---------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(X_train.shape[1], len(set(y_train))).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "# 3. Training\n",
    "# ------------\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # 4. Evaluation\n",
    "    # ---------------\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train_tensor)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        accuracy = (predicted == y_train_tensor).sum().item() / len(y_train_tensor)\n",
    "        print(f\"Training Accuracy: {accuracy}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "f26483133cdd92e7b8e9c0a10475b9ecffde5321"
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load your data\n",
    "# data = pd.read_csv(\"cleaned_2022_parking_citation.csv\")\n",
    "\n",
    "# # Preprocess the data (similar to what we did above)\n",
    "# data = data.dropna(subset=['Violation Description'])\n",
    "# features = ['RP State Plate', 'Make', 'Body Style', 'Color Description', 'Agency Description', 'Issue Hour']\n",
    "# X = data[features]\n",
    "# X = X.fillna('Unknown')\n",
    "\n",
    "# label_encoders = {}\n",
    "# for col in X.select_dtypes(include=['object']).columns:\n",
    "#     le = LabelEncoder()\n",
    "#     X[col] = le.fit_transform(X[col])\n",
    "#     label_encoders[col] = le\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X[['Issue time', 'Issue Hour']] = scaler.fit_transform(X[['Issue time', 'Issue Hour']])\n",
    "# y = LabelEncoder().fit_transform(data['Violation Description'])\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train the XGBoost classifier\n",
    "# clf = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_train)), random_state=42, use_label_encoder=False)\n",
    "# clf.fit(X_train, y_train, eval_metric='mlogloss')\n",
    "\n",
    "# # Get training accuracy (you can also get testing accuracy if you wish)\n",
    "# train_accuracy = clf.score(X_train, y_train)\n",
    "# print(f\"Training Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
